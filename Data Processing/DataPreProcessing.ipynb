{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\shirish\\anaconda3\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from pandas) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from pandas) (2018.7)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from pandas) (1.15.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shirish\\anaconda3\\lib\\site-packages (1.15.4)\n",
      "Collecting json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement json (from versions: )\n",
      "No matching distribution found for json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\shirish\\anaconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from gensim) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from gensim) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart_open>=1.2.1 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from gensim) (1.8.4)\n",
      "Requirement already satisfied: bz2file in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from smart_open>=1.2.1->gensim) (0.98)\n",
      "Requirement already satisfied: requests in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from smart_open>=1.2.1->gensim) (2.21.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from smart_open>=1.2.1->gensim) (1.9.162)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from smart_open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from requests->smart_open>=1.2.1->gensim) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from requests->smart_open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from requests->smart_open>=1.2.1->gensim) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from requests->smart_open>=1.2.1->gensim) (1.24.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.162 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from boto3->smart_open>=1.2.1->gensim) (1.12.163)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from boto3->smart_open>=1.2.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from boto3->smart_open>=1.2.1->gensim) (0.2.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.162->boto3->smart_open>=1.2.1->gensim) (2.7.5)\n",
      "Requirement already satisfied: docutils>=0.10 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.162->boto3->smart_open>=1.2.1->gensim) (0.14)\n",
      "Requirement already satisfied: textblob in c:\\users\\shirish\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from textblob) (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\shirish\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (3.4.0.3)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\shirish\\anaconda3\\lib\\site-packages (1.2.15)\n",
      "Collecting urllib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement urllib (from versions: )\n",
      "No matching distribution found for urllib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyodbc in c:\\users\\shirish\\anaconda3\\lib\\site-packages (4.0.25)\n",
      "Requirement already satisfied: pymysql in c:\\users\\shirish\\anaconda3\\lib\\site-packages (0.9.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "! pip install numpy\n",
    "! pip install json\n",
    "! pip install gensim\n",
    "! pip install textblob\n",
    "! pip install sqlalchemy\n",
    "! pip install urllib\n",
    "! pip install pyodbc\n",
    "! pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from gensim.summarization import summarize, keywords\n",
    "from textblob import TextBlob\n",
    "from sqlalchemy import *\n",
    "import urllib\n",
    "import pyodbc\n",
    "import pymysql\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Please provide the source path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"Please provide the source data path\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Slicing the data and saving it in json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_json(path+r'\\sample-1M.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_np_array =np.array_split(data_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10,1):\n",
    "    test_df = pd.DataFrame(data_df_np_array[i])\n",
    "    test_df.to_json(path+r'\\Dataset_'+str(i)+'.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Retrieve the sliced data and process to find summarization, keywords and sentiments out of the articles. \n",
    "    Note: The processing in i7 and 8GB RAM system took minimum 2 hours for each sliced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)\n",
    "dirName = 'Summarized Test'\n",
    "os.mkdir(dirName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c53b6564d0ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Summarization'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummarization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Keywords'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_keywords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiment_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    939\u001b[0m         \u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[0;32m   2565\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2566\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2567\u001b[1;33m                     \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2568\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2569\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m   2522\u001b[0m         \"\"\"The object has called back to us saying maybe it has changed.\n\u001b[0;32m   2523\u001b[0m         \"\"\"\n\u001b[1;32m-> 2524\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2526\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value, check)\u001b[0m\n\u001b[0;32m   4250\u001b[0m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4252\u001b[1;33m         \u001b[0mblknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4253\u001b[0m         \u001b[0mblklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0,1,1):\n",
    "    data = pd.read_json(path+r'\\Dataset_'+str(i)+'.json', lines=True)\n",
    "    data['Summarization'] = ''\n",
    "    data['Keywords'] = ''\n",
    "    data['Sentiment'] = ''\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            summarization = summarize(data['content'][i])\n",
    "            text_keywords = keywords(data['content'][i]).replace('\\n',',')\n",
    "            textblob_object = TextBlob(data['content'][i])\n",
    "            sentiment_value = textblob_object.sentiment.polarity\n",
    "        except:\n",
    "            continue\n",
    "        data['Summarization'][i] = summarization\n",
    "        data['Keywords'][i] = text_keywords\n",
    "        data['Sentiment'][i] = round(sentiment_value,2)\n",
    "        \n",
    "    data.to_json(path+r'\\Summarized Test\\Dataset_'+str(i)+'.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Now lets load the processed data to MySql. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-20 12:50:28,187 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE data (\n",
      "\t`Keywords` TEXT, \n",
      "\t`Sentiment` FLOAT, \n",
      "\t`Summarization` TEXT, \n",
      "\tcontent TEXT, \n",
      "\tid TEXT, \n",
      "\t`media-type` TEXT, \n",
      "\tpublished DATE, \n",
      "\tsource TEXT, \n",
      "\ttitle TEXT\n",
      ")\n",
      "\n",
      "\n",
      "2019-08-20 12:50:28,188 INFO sqlalchemy.engine.base.Engine {}\n",
      "2019-08-20 12:50:28,278 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2019-08-20 12:50:28,279 INFO sqlalchemy.engine.base.Engine ALTER DATABASE dataset CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci;\n",
      "2019-08-20 12:50:28,280 INFO sqlalchemy.engine.base.Engine {}\n",
      "2019-08-20 12:50:28,281 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2019-08-20 12:50:28,283 INFO sqlalchemy.engine.base.Engine ALTER TABLE data CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\n",
      "2019-08-20 12:50:28,283 INFO sqlalchemy.engine.base.Engine {}\n",
      "2019-08-20 12:50:28,434 INFO sqlalchemy.engine.base.Engine COMMIT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"CREATE TABLE 'dataset'(\\n `Keywords` mediumtext COLLATE utf8mb4_unicode_ci,\\n `Sentiment` float DEFAULT '0',\\n `Summarization` mediumtext COLLATE utf8mb4_unicode_ci,\\n `content` longtext COLLATE utf8mb4_unicode_ci,\\n `id` mediumtext COLLATE utf8mb4_unicode_ci,\\n `media-type` mediumtext COLLATE utf8mb4_unicode_ci,\\n `published` date DEFAULT NULL,\\n `source` mediumtext COLLATE utf8mb4_unicode_ci,\\n `title` mediumtext COLLATE utf8mb4_unicode_ci,\\n KEY `PublishedDate_Index` (`published`),\\n FULLTEXT KEY `KeyWords_Index` (`Keywords`),\\n FULLTEXT KEY `id_index` (`id`)\\n ) ENGINE=MyISAM DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci)\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost\"\n",
    "                       .format(user=\"root\",\n",
    "                               pw=\"\",),pool_timeout=20, pool_recycle=3600)\n",
    "\n",
    "engine.execute(\"Create database infovis\")\n",
    "\n",
    "engine.execute(\"USE infovis\")\n",
    "\n",
    "engine.echo = True\n",
    "\n",
    "metadata = MetaData(engine)\n",
    "\n",
    "users = Table('dataset', metadata,\n",
    "             Column('Keywords', Text),\n",
    "             Column('Sentiment', FLOAT),\n",
    "             Column('Summarization', Text),\n",
    "             Column('content', Text),\n",
    "             Column('id', Text),\n",
    "             Column('media-type', Text),\n",
    "             Column('published', Date),\n",
    "             Column('source', Text),\n",
    "             Column('title', Text)\n",
    "        )\n",
    "users.create()\n",
    "\n",
    "engine.execute(\"ALTER DATABASE infovis CHARACTER SET = utf8mb4 COLLATE = utf8mb4_unicode_ci;\")\n",
    "engine.execute(\"ALTER TABLE dataset CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10,1):\n",
    "    data = pd.read_json(path+r'\\Summarized Test\\Dataset_'+str(i)+'.json',lines=True)\n",
    "    data['published'] = pd.to_datetime(data['published'])\n",
    "    data['published'] = data['published'].dt.date\n",
    "    temp = data['Sentiment']\n",
    "    temp.replace(r'', np.nan, inplace=True)\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data['Sentiment'] = test\n",
    "    data.to_sql(con=engine, name='data', if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create indexing in the database for fast querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute('create fulltext index Keyword_Index on data(Keywords)')\n",
    "engine.execute('create index publishedDate_Index on data(published)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
